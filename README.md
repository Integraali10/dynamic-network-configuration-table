# Dynamic network configuration solutions
My collection of deep learning solutions based on dynamic network configuration and attention mechanism. Awesome list of inspiration is [here](https://github.com/D-X-Y/Awesome-AutoDL)

| Article |Year	| Affiliation 	| Code 	| Smol Description 	| Key Words 	|
|---------|---- |-------------	|------	|------------------	|-----------	|
|![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)[Dynamic Algorithm Configuration:Foundation of a New Meta-Algorithmic Framework](https://ecai2020.eu/papers/1237_paper.pdf) [[blog](https://www.automl.org/dynamic-algorithm-configuration/)]|2020|Germany|[code](https://github.com/automl/DAC)|                  	|Hyperparameter optimization       	|
|![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)[BOHB: Robust and Efficient Hyperparameter Optimization at Scale](https://www.automl.org/blog_bohb/) [[blog](https://www.automl.org/blog_bohb/)]|2018|Germany|[code](https://github.com/automl/HpBandSter)|                  	|Hyperparameter optimization           	|
|![#1589F0](https://via.placeholder.com/15/1589F0/000000?text=+)[Not All Attention Is Needed: Gated Attention Network for Sequence Data](https://arxiv.org/abs/1912.00349) [[blog]()]|2019|Hong-Kong, Amazon| -/- |                   | Attention mechanism, dynamic network configuration, sequential models, NLP, text classification|
|![#f03c15](https://via.placeholder.com/15/f03c15/000000?text=+)[Multi-Dimension Modulation for Image Restoration with Dynamic Controllable Residual Learning](https://arxiv.org/pdf/1912.05293v1.pdf) [[review](https://syncedreview.com/2020/08/15/interactive-multi-dimension-modulation-with-dynamic-controllable-residual-learning-for-image-restoration/)] |2019|China|[code](https://github.com/hejingwenhejingwen/CResMD)|                   | Image restoration, interactive multi-dimension modulation|
|![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)[MixPath: A Unified Approach for One-shot Neural Architecture Search](https://arxiv.org/abs/2001.05887)|2020|China, Xiaomi|[code](https://github.com/xiaomi-automl/MixPath)||supernet, multi-path search space|
|![#f03c15](https://via.placeholder.com/15/f03c15/000000?text=+)[Graph Attention Networks](https://arxiv.org/abs/1710.10903) [[blog](https://petar-v.com/GAT/)]|2018|Europe, Canada|[code](https://github.com/PetarV-/GAT)| |graph, attention mechanism, graph-structured data|
|![#f03c15](https://via.placeholder.com/15/f03c15/000000?text=+)[Fully Convolutional Network with Multi-Step Reinforcement Learningfor Image Processing](https://arxiv.org/pdf/1811.04323.pdf) [[review](https://vitalab.github.io/article/2019/01/22/FCN_MultiStepRL_ImageProcessing.html)}|2018|Japan|||RL, pixel-wise agents, image restoration|
|![#c5f015](https://via.placeholder.com/15/c5f015/000000?text=+)[Balanced One-shot Neural Architecture Optimization](https://arxiv.org/abs/1909.10815)|2019|China, Microsoft Asia|-/-||supernet, neural architecture search|

Interesting popular articles:

- [Model ensembling with cuML and Scikit-learn](https://medium.com/rapids-ai/100x-faster-machine-learning-model-ensembling-with-rapids-cuml-and-scikit-learn-meta-estimators-d869788ee6b1)
