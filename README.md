# Dynamic network configuration solutions
Collection of rare deep learning solutions based on dynamic network configuration and attention mechanism

| Article 	| Affiliation/Country  	| Code 	| Smol Description 	| Key Words 	|
|---------	|-------------	|------	|------------------	|-----------	|
|[Dynamic Algorithm Configuration:Foundation of a New Meta-Algorithmic Framework](https://ecai2020.eu/papers/1237_paper.pdf) [[blog](https://www.automl.org/dynamic-algorithm-configuration/)]|Germany|[code](https://github.com/automl/DAC)|                  	|Hyperparameter optimization       	|
|[BOHB: Robust and Efficient Hyperparameter Optimization at Scale](https://www.automl.org/blog_bohb/) [[blog](https://www.automl.org/blog_bohb/)]|Germany|[code](https://github.com/automl/HpBandSter)|                  	|Hyperparameter optimization           	|
|[Not All Attention Is Needed: Gated Attention Network for Sequence Data](https://arxiv.org/abs/1912.00349) [[blog]()]|The Hong Kong University of Science and Technology, Hong Kong; "Work was done prior to joining AmazonÂ©,2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved" | -/- |                   | Attention mechanism, dynamic network configuration, sequentioal models, NLP, text classification|
|          	|               |       |                   |             |
